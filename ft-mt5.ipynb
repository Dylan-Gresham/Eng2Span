{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T05:19:15.963221Z",
     "start_time": "2025-03-27T05:19:13.698629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import evaluate\n",
    "import accelerate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    ")\n",
    "\n",
    "MODEL_REPO = \"google/mT5-small\"\n",
    "PREFIX = \"translate English to Spanish: \""
   ],
   "id": "dbfcebbe7f6d4b5f",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T05:19:22.516837Z",
     "start_time": "2025-03-27T05:19:15.966576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "meteor = evaluate.load(\"meteor\")\n",
    "ter = evaluate.load(\"ter\")\n",
    "METRICS = [\n",
    "    (\"BLEU\", bleu),\n",
    "    (\"ROUGE\", rouge),\n",
    "    (\"METEOR\", meteor),\n",
    "    (\"TER\", ter),\n",
    "]"
   ],
   "id": "c2cab891426cb4cd",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/midge/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/midge/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/midge/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T05:19:23.186026Z",
     "start_time": "2025-03-27T05:19:22.692551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.read_csv(\"./data/combined.data\")\n",
    "train = data.loc[data[\"split\"] != \"test\"]\n",
    "test = data.loc[data[\"split\"] == \"test\"]"
   ],
   "id": "51f5243f9a54be83",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T05:19:24.686804Z",
     "start_time": "2025-03-27T05:19:23.192202Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer = AutoTokenizer.from_pretrained(MODEL_REPO)",
   "id": "c7be4ef2a82ce4c6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "/home/midge/repos/bsu/spring_2025/nlp/Eng2Span/.venv/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:559: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T05:19:24.713074Z",
     "start_time": "2025-03-27T05:19:24.711032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_text(sample):\n",
    "    input = PREFIX + str(sample[0])\n",
    "    target = str(sample[1])\n",
    "    return tokenizer(input, text_target=target, max_length=128, truncation=True)\n",
    "\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "\n",
    "    return preds, labels"
   ],
   "id": "efd8f4df08565450",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T05:20:08.849676Z",
     "start_time": "2025-03-27T05:19:24.752277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenized_train_data = [\n",
    "    preprocess_text((row[\"en\"], row[\"es\"])) for _, row in train.iterrows()\n",
    "]\n",
    "tokenized_test_data = [\n",
    "    preprocess_text((row[\"en\"], row[\"es\"])) for _, row in test.iterrows()\n",
    "]"
   ],
   "id": "9611f173f2e146f5",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T05:20:08.876990Z",
     "start_time": "2025-03-27T05:20:08.875555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer, model=MODEL_REPO, return_tensors=\"pt\"\n",
    ")"
   ],
   "id": "e6a21678f8832861",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T05:20:08.919556Z",
     "start_time": "2025-03-27T05:20:08.917071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = {}\n",
    "    for name, metric in METRICS:\n",
    "        result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "        result = {name: result[\"score\"]}\n",
    "\n",
    "    prediction_lens = [\n",
    "        np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds\n",
    "    ]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "\n",
    "    return result"
   ],
   "id": "70760c2bd49805eb",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T05:20:10.375041Z",
     "start_time": "2025-03-27T05:20:08.962022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_REPO)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"mt5\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=3,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_data,\n",
    "    eval_dataset=tokenized_test_data,\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ],
   "id": "ee889bfdcfdd7471",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T05:42:56.649009Z",
     "start_time": "2025-03-27T05:20:10.400688Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.train()",
   "id": "e0997fe803090aaf",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9936' max='29805' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 9936/29805 15:43 < 31:26, 10.53 it/s, Epoch 1/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2484' max='2484' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2484/2484 06:57]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mZeroDivisionError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/repos/bsu/spring_2025/nlp/Eng2Span/.venv/lib/python3.12/site-packages/transformers/trainer.py:2245\u001B[39m, in \u001B[36mTrainer.train\u001B[39m\u001B[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[39m\n\u001B[32m   2243\u001B[39m         hf_hub_utils.enable_progress_bars()\n\u001B[32m   2244\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2245\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2246\u001B[39m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m=\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2247\u001B[39m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m=\u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2248\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2249\u001B[39m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2250\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/repos/bsu/spring_2025/nlp/Eng2Span/.venv/lib/python3.12/site-packages/transformers/trainer.py:2647\u001B[39m, in \u001B[36mTrainer._inner_training_loop\u001B[39m\u001B[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[39m\n\u001B[32m   2644\u001B[39m     \u001B[38;5;28mself\u001B[39m.control.should_training_stop = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m   2646\u001B[39m \u001B[38;5;28mself\u001B[39m.control = \u001B[38;5;28mself\u001B[39m.callback_handler.on_epoch_end(args, \u001B[38;5;28mself\u001B[39m.state, \u001B[38;5;28mself\u001B[39m.control)\n\u001B[32m-> \u001B[39m\u001B[32m2647\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_maybe_log_save_evaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtr_loss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_norm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstart_time\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2649\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m DebugOption.TPU_METRICS_DEBUG \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.args.debug:\n\u001B[32m   2650\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m is_torch_xla_available():\n\u001B[32m   2651\u001B[39m         \u001B[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/repos/bsu/spring_2025/nlp/Eng2Span/.venv/lib/python3.12/site-packages/transformers/trainer.py:3093\u001B[39m, in \u001B[36mTrainer._maybe_log_save_evaluate\u001B[39m\u001B[34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time)\u001B[39m\n\u001B[32m   3091\u001B[39m metrics = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   3092\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.control.should_evaluate:\n\u001B[32m-> \u001B[39m\u001B[32m3093\u001B[39m     metrics = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_evaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3094\u001B[39m     is_new_best_metric = \u001B[38;5;28mself\u001B[39m._determine_best_metric(metrics=metrics, trial=trial)\n\u001B[32m   3096\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.args.save_strategy == SaveStrategy.BEST:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/repos/bsu/spring_2025/nlp/Eng2Span/.venv/lib/python3.12/site-packages/transformers/trainer.py:3047\u001B[39m, in \u001B[36mTrainer._evaluate\u001B[39m\u001B[34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001B[39m\n\u001B[32m   3046\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_evaluate\u001B[39m(\u001B[38;5;28mself\u001B[39m, trial, ignore_keys_for_eval, skip_scheduler=\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[32m-> \u001B[39m\u001B[32m3047\u001B[39m     metrics = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3048\u001B[39m     \u001B[38;5;28mself\u001B[39m._report_to_hp_search(trial, \u001B[38;5;28mself\u001B[39m.state.global_step, metrics)\n\u001B[32m   3050\u001B[39m     \u001B[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/repos/bsu/spring_2025/nlp/Eng2Span/.venv/lib/python3.12/site-packages/transformers/trainer_seq2seq.py:197\u001B[39m, in \u001B[36mSeq2SeqTrainer.evaluate\u001B[39m\u001B[34m(self, eval_dataset, ignore_keys, metric_key_prefix, **gen_kwargs)\u001B[39m\n\u001B[32m    195\u001B[39m \u001B[38;5;28mself\u001B[39m.gather_function = \u001B[38;5;28mself\u001B[39m.accelerator.gather\n\u001B[32m    196\u001B[39m \u001B[38;5;28mself\u001B[39m._gen_kwargs = gen_kwargs\n\u001B[32m--> \u001B[39m\u001B[32m197\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43meval_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/repos/bsu/spring_2025/nlp/Eng2Span/.venv/lib/python3.12/site-packages/transformers/trainer.py:4136\u001B[39m, in \u001B[36mTrainer.evaluate\u001B[39m\u001B[34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001B[39m\n\u001B[32m   4133\u001B[39m start_time = time.time()\n\u001B[32m   4135\u001B[39m eval_loop = \u001B[38;5;28mself\u001B[39m.prediction_loop \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.args.use_legacy_prediction_loop \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m.evaluation_loop\n\u001B[32m-> \u001B[39m\u001B[32m4136\u001B[39m output = \u001B[43meval_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   4137\u001B[39m \u001B[43m    \u001B[49m\u001B[43meval_dataloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4138\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdescription\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mEvaluation\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   4139\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001B[39;49;00m\n\u001B[32m   4140\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# self.args.prediction_loss_only\u001B[39;49;00m\n\u001B[32m   4141\u001B[39m \u001B[43m    \u001B[49m\u001B[43mprediction_loss_only\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcompute_metrics\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   4142\u001B[39m \u001B[43m    \u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4143\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   4144\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4146\u001B[39m total_batch_size = \u001B[38;5;28mself\u001B[39m.args.eval_batch_size * \u001B[38;5;28mself\u001B[39m.args.world_size\n\u001B[32m   4147\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmetric_key_prefix\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m_jit_compilation_time\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m output.metrics:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/repos/bsu/spring_2025/nlp/Eng2Span/.venv/lib/python3.12/site-packages/transformers/trainer.py:4425\u001B[39m, in \u001B[36mTrainer.evaluation_loop\u001B[39m\u001B[34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001B[39m\n\u001B[32m   4423\u001B[39m     eval_set_kwargs[\u001B[33m\"\u001B[39m\u001B[33mlosses\u001B[39m\u001B[33m\"\u001B[39m] = all_losses \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mloss\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m args.include_for_metrics \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   4424\u001B[39m     eval_set_kwargs[\u001B[33m\"\u001B[39m\u001B[33minputs\u001B[39m\u001B[33m\"\u001B[39m] = all_inputs \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33minputs\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m args.include_for_metrics \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m4425\u001B[39m     metrics = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcompute_metrics\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   4426\u001B[39m \u001B[43m        \u001B[49m\u001B[43mEvalPrediction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpredictions\u001B[49m\u001B[43m=\u001B[49m\u001B[43mall_preds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel_ids\u001B[49m\u001B[43m=\u001B[49m\u001B[43mall_labels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43meval_set_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4427\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4428\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m metrics \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   4429\u001B[39m     metrics = {}\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[8]\u001B[39m\u001B[32m, line 15\u001B[39m, in \u001B[36mcompute_metrics\u001B[39m\u001B[34m(eval_preds)\u001B[39m\n\u001B[32m     13\u001B[39m result = {}\n\u001B[32m     14\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m name, metric \u001B[38;5;129;01min\u001B[39;00m METRICS:\n\u001B[32m---> \u001B[39m\u001B[32m15\u001B[39m     result = \u001B[43mmetric\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcompute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpredictions\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdecoded_preds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreferences\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdecoded_labels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     16\u001B[39m     result = {name: result[\u001B[33m\"\u001B[39m\u001B[33mscore\u001B[39m\u001B[33m\"\u001B[39m]}\n\u001B[32m     18\u001B[39m prediction_lens = [\n\u001B[32m     19\u001B[39m     np.count_nonzero(pred != tokenizer.pad_token_id) \u001B[38;5;28;01mfor\u001B[39;00m pred \u001B[38;5;129;01min\u001B[39;00m preds\n\u001B[32m     20\u001B[39m ]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/repos/bsu/spring_2025/nlp/Eng2Span/.venv/lib/python3.12/site-packages/evaluate/module.py:467\u001B[39m, in \u001B[36mEvaluationModule.compute\u001B[39m\u001B[34m(self, predictions, references, **kwargs)\u001B[39m\n\u001B[32m    465\u001B[39m inputs = {input_name: \u001B[38;5;28mself\u001B[39m.data[input_name] \u001B[38;5;28;01mfor\u001B[39;00m input_name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m._feature_names()}\n\u001B[32m    466\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m temp_seed(\u001B[38;5;28mself\u001B[39m.seed):\n\u001B[32m--> \u001B[39m\u001B[32m467\u001B[39m     output = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_compute\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mcompute_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    469\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.buf_writer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    470\u001B[39m     \u001B[38;5;28mself\u001B[39m.buf_writer = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--bleu/9e0985c1200e367cce45605ce0ecb5ede079894e0f24f54613fca08eeb8aff76/bleu.py:122\u001B[39m, in \u001B[36mBleu._compute\u001B[39m\u001B[34m(self, predictions, references, tokenizer, max_order, smooth)\u001B[39m\n\u001B[32m    120\u001B[39m references = [[tokenizer(r) \u001B[38;5;28;01mfor\u001B[39;00m r \u001B[38;5;129;01min\u001B[39;00m ref] \u001B[38;5;28;01mfor\u001B[39;00m ref \u001B[38;5;129;01min\u001B[39;00m references]\n\u001B[32m    121\u001B[39m predictions = [tokenizer(p) \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m predictions]\n\u001B[32m--> \u001B[39m\u001B[32m122\u001B[39m score = \u001B[43mcompute_bleu\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    123\u001B[39m \u001B[43m    \u001B[49m\u001B[43mreference_corpus\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreferences\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtranslation_corpus\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpredictions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_order\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmax_order\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msmooth\u001B[49m\u001B[43m=\u001B[49m\u001B[43msmooth\u001B[49m\n\u001B[32m    124\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    125\u001B[39m (bleu, precisions, bp, ratio, translation_length, reference_length) = score\n\u001B[32m    126\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[32m    127\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mbleu\u001B[39m\u001B[33m\"\u001B[39m: bleu,\n\u001B[32m    128\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mprecisions\u001B[39m\u001B[33m\"\u001B[39m: precisions,\n\u001B[32m   (...)\u001B[39m\u001B[32m    132\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mreference_length\u001B[39m\u001B[33m\"\u001B[39m: reference_length,\n\u001B[32m    133\u001B[39m }\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--bleu/9e0985c1200e367cce45605ce0ecb5ede079894e0f24f54613fca08eeb8aff76/nmt_bleu.py:108\u001B[39m, in \u001B[36mcompute_bleu\u001B[39m\u001B[34m(reference_corpus, translation_corpus, max_order, smooth)\u001B[39m\n\u001B[32m    106\u001B[39m   bp = \u001B[32m1.\u001B[39m\n\u001B[32m    107\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m108\u001B[39m   bp = math.exp(\u001B[32m1\u001B[39m - \u001B[32;43m1.\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m/\u001B[49m\u001B[43m \u001B[49m\u001B[43mratio\u001B[49m)\n\u001B[32m    110\u001B[39m bleu = geo_mean * bp\n\u001B[32m    112\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m (bleu, precisions, bp, ratio, translation_length, reference_length)\n",
      "\u001B[31mZeroDivisionError\u001B[39m: float division by zero"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T05:49:39.423763Z",
     "start_time": "2025-03-27T05:49:38.750065Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.save_model(\"mt5\")",
   "id": "b52c8208215998dd",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# import torch\n",
    "# import gc\n",
    "\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ],
   "id": "257fc6fa79e75db",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
